{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a749d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Jayanthi Challa\n",
    "# Campus: VIT-AP\n",
    "# Email: jayanthi.20mis7066@vitap.ac.in\n",
    "# Reg.No.: 20MIS7066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222339f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 1 classes.\n",
      "Found 157 images belonging to 1 classes.\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 124s 28s/step - loss: 92.6158 - accuracy: 0.1933 - val_loss: 307.7137 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 115s 26s/step - loss: 597.6215 - accuracy: 0.0000e+00 - val_loss: 1456.7888 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 109s 25s/step - loss: 2320.6270 - accuracy: 0.0000e+00 - val_loss: 4545.7939 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 108s 25s/step - loss: 6432.9302 - accuracy: 0.0000e+00 - val_loss: 10916.2305 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 108s 25s/step - loss: 14957.9531 - accuracy: 0.0000e+00 - val_loss: 22993.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 109s 26s/step - loss: 29884.3730 - accuracy: 0.0000e+00 - val_loss: 43307.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 109s 25s/step - loss: 53318.1250 - accuracy: 0.0000e+00 - val_loss: 73664.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 108s 24s/step - loss: 84031.1328 - accuracy: 0.0000e+00 - val_loss: 116239.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 108s 24s/step - loss: 132715.0625 - accuracy: 0.0000e+00 - val_loss: 177273.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 110s 25s/step - loss: 197754.9844 - accuracy: 0.0000e+00 - val_loss: 256226.2188 - val_accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 60s 12s/step - loss: 256226.1875 - accuracy: 0.0000e+00\n",
      "Validation loss: 256226.1875\n",
      "Validation accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the necessary libraries and modules.\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import zipfile\n",
    "\n",
    "# Step 2: Load and Preprocess the Dataset\n",
    "zip_file_path = r\"C:\\Users\\chall\\OneDrive\\Desktop\\VIT\\Long Sem(2022-23)\\SPJ2001\\Artificial Intelligence - SmartInternz\\archive.zip\"\n",
    "extract_folder = r\"C:\\Users\\chall\\OneDrive\\Desktop\\VIT\\Long Sem(2022-23)\\SPJ2001\\Artificial Intelligence - SmartInternz\"\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "train_data_dir = os.path.join(extract_folder, 'train_data')\n",
    "val_data_dir = os.path.join(extract_folder, 'test_data')\n",
    "\n",
    "# Define data augmentation and preprocessing parameters\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set batch size and image dimensions\n",
    "batch_size = 32\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "\n",
    "# Step 3: Create data generators for training and validation\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_data_generator.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Step 4: Build the CNN Model\n",
    "num_classes = 10\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the Model\n",
    "model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print('Validation loss:', loss)\n",
    "print('Validation accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
